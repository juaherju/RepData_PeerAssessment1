X <-1
print(x)
print(X)
x
X
q()
R.version.string
install.packages("swirl")
library(swirl)
ls()
rm(list=ls())
library(swirl)
swirl()
5+7
x<-5+7
x
y<-x-3
y
z<-c(1.1,9,3.14)
?c
z
c(z,555,z)
z*2+100
my_sqrt <-sqrt(z-1)
my_sqrt
my_div<-z/my_sqrt
my_div
c(1,2,3,4)+c(0,10)
c(1,2,3,4)+c(0,10,100)
z*2+1000
my_div
ls
ls()
q()
install.packages("devtools")
library(devtools)
find_rtools()
GETWD()
getwd()
library(data.table)
install.packages("data.table")
library(data.table)
example(data.table)
update.packages()
fileUrl <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl,destfile=".\datos.csv", method="curl")
download.file(fileUrl,destfile="./datos.csv", method="curl")
fileUrl <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv?accesType=DOWNLOAD"
download.file(fileUrl,destfile="./datos.csv", method="curl")
download.file(fileUrl,destfile="datos.csv", method="curl")
fileUrl <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl,destfile="datos.csv", method="curl")
install.packages(curl)
download.file(fileUrl,destfile="datos.csv")
data<-read.table("datos.csv")
head(data)
data <-read.table("datos.csv",sep=",", header=TRUE)
head(data)
data2 <-read.csv("datos.csv")
head(data2)
subset<-data[data$VAL=24]
subset<-data[data$VAL>23]
subset<-data[,data$VAL>23]
subset<-data[wich(data$VAL=24)]
fileUrl <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl,destfile="datos.csv")
data<-read.table("datos.csv")
data2 <-read.csv("datos.csv")
head(data)
head(data2)
data2[,.N,by=VAL]
data[,.N,by=VAL]
data2[data2$VAL==24,]
View(data2)
data[2]
data2[2]
data2[2,]
data2[data2$VAL=24]
head(data, 10)
data2[data2$VAL==24]
data2[2,]
data2[3,]
data2[data2$VAL==24,]
data2[data2$VAL=="24",]
data2[2,]
View(data2)
names(data2)
valor <-data2[data2$VAL]
valor <-data2$VAL
valor[valor=24]
length(valor)
valor
sub<-subset(data2, VAL>23)
rows(sub)
nrow(sub)
View(data2)
urlexcel <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(urlexcel,destfile="GAP.xlsx")
library(xlsx)
install.packages(xlsx)
"xlsx"
install.packages("xlsx")
library(xlsx)
install.packages("rjava")
y
9
install.packages("rJava")
library(xlsx)
library(rJava)
library("xlsx", lib.loc="C:/Program Files/R/R-3.2.2/library")
install.packages("xlsx")
library("xlsx", lib.loc="C:/Program Files/R/R-3.2.2/library")
detach("package:xlsx", unload=TRUE)
library("rJava", lib.loc="C:/Program Files/R/R-3.2.2/library")
library(xlsx)
R.version()
R.Version()
library(xlsx)
library(rJava)
lilbrary(XML)
install.packages("XML")
library(XML)
fileUrl <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <-xmlTreeParse(fileUrl,useInternal=TRUE)
doc <-xmlTreeParse(fileUrl,useInternalNodes =TRUE)
fileUrl <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <-xmlTreeParse(fileUrl)
doc <- xmlTreeParse(sub("s", "", fileURL), useInternal = TRUE)
doc <- xmlTreeParse(sub("s", "", fileUrl), useInternal = TRUE)
rootNode <-xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
xmlApply(rootNode, "//zipcode", xmlValue)
xpathSApply(rootNode, "//zipcode", xmlValue)
zip<- xpathSApply(rootNode, "//zipcode", xmlValue)
zip
z <- zip[zip=21231]
z
names(zip)
zipo <-data.frame(zip)
zipo
names(zipo)
z <- subset(zipo, zip==21231)
nrow(z)
urlcsv <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(urlcsv, "americancommitsurvey.csv")
tabla <-fread("americancommitsurvey.csv")
library(data.table)
tabla <-fread("americancommitsurvey.csv")
DT <-fread("americancommitsurvey.csv")
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
mean(DT$pwgtp15,by=DT$SEX)
View(DT)
tapply(DT$pwgtp15,DT$SEX,mean)
DT[,mean(pwgtp15),by=SEX]
sapply(split(DT$pwgtp15,DT$SEX),mean)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time((mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(rowMeans(DT)[DT$SEX==1])
system.time(rowMeans(DT)[DT$SEX==2])
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system,time(DT[,mean(pwgtp15),by=SEX])
DT[,mean(pwgtp15),by=SEX]
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(rowMeans(DT)[DT$SEX==1])
system.time(rowMeans(DT)[DT$SEX==2])
mean(DT$pwgtp15,by=DT$SEX)
tapply(DT$pwgtp15,DT$SEX,mean)
DT[,mean(pwgtp15),by=SEX]
sapply(split(DT$pwgtp15,DT$SEX),mean)
mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT[DT$SEX==1,]$pwgtp15)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
f <- file.path(getwd(), "DATA.gov_NGAP.xlsx")
download.file(url, f)
rows <- 18:23
cols <- 7:15
dat <- read.xlsx(f, 1, colIndex = cols, rowIndex = rows)
packages <- c("data.table", "xlsx", "XML")
sapply(packages, require, character.only = TRUE, quietly = TRUE)
install.packages("KernSmooth")
library(KernSmooth)
library(xlsx)
colIndex <-18:23
rowIndex <-18:23
colIndex <-7:15
datos<- read.xlsx("gap2.xlsx", sheetIndex = 1, colIndex, rowIndex)
rowIndx <-18:23
colIndx <-7:15
datos<- read.xlsx(file = "gap2.xlsx", sheetIndex = 1, colIndex=colIndx, startRow = 18, endRow = 23, header = TRUE)
datos<- read.xlsx(file = "gap2.xlsx")
datos<- read.xlsx(file = "gap2.xlsx", sheetIndex = 1)
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(url=fileUrl1, destfile="gov_NGAP.xlsx", mode="w", method="curl")
download.file(url=fileUrl1, destfile="gov_NGAP.xlsx", mode="w")
downloadeddate <- date()
downloadeddate
cube <- function(x,n){}
cube <- function(x,n){}
cube <- function(x,n){x^3}
cube(3)
x<-1:10
if(x>5){x<-0}
x>5
x<-0
x
x<1:10
x<-<1:10
x<-1:10
if(x>5){}
x<-5
y<- if(x<3){NA}else{10}
y
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z<-10
f(3)
install.packages('RMySQL',type='source')
library(RMySQL)
ucscDb<- dbConnect(MySQL(), user=”genome”, host=”genome-mysql.cse.ucsc.edu”)
ucscDb<- dbConnect(MySQL(), user="genome", host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucsDb,"show databases;")
result <- dbGetQuery(ucscDb,"show databases;")
dbDisconnect(ucscDb)
result
source("http://bioconductor.org/biocLite,R")
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
url <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv""
url <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url,"amcomsur.csv")
acs <-read.csv("amcomsur.csv")
head(acs)
sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
install.packages(sqldf)
install.packages("sqldf")
library(sqldf)
sqldf("select pwgtp1 from acs where AGEP < 50")
environment()
sqldf(acs,"select pwgtp1 from acs where AGEP < 50")
acs <-data.table(read.csv("amcomsur.csv"))
library(data.table)
acs <-data.table(read.csv("amcomsur.csv"))
sqldf(acs,"select pwgtp1 from acs where AGEP < 50")
unique(acs$AGEP)
?unique
?unique
con <-url("http://biostat.jhsph.edu/~jleek/contact.html")
?readLines
?read.table
read.table(con,skip = 9, nrows=1)
cadena(read.table(con,skip=9, nrows=1))
cadena<-read.table(con,skip=9, nrows=1)
read.table(con,skip = 9, nrows=1)
close(con)
close(con=con)
read.table(con,skip = 9, nrows=1)
con <-url("http://biostat.jhsph.edu/~jleek/contact.html")
read.table(con,skip = 9, nrows=1)
con <-url("http://biostat.jhsph.edu/~jleek/contact.html")
cadena<-read.table(con,skip=9, nrows=1)
nchar(cadena)
con <-url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlcode <- readlines(con)
htmlcode <- readLines(con)
close(con)
nchar(htmlcode[10])
nchar(htmlcode[20])
nchar(htmlcode[30])
nchar(htmlcode[100])
con <-url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"")
con <-url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
download.file(con, "archivofor.for")
dir <-"https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(dir, "archivofor.for")
datos <-read.table("archivofor.for",skip = 5)
install.packages("foreign")
library(foreign)
datos <-read.spss("archivofor.for")
dir <-"https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
head(d)
d <- read.fwf(dir, w, header=FALSE, skip=4, col.names=colNames)
head(d)
names(d)
d <- d[, grep("^[^filler]", names(d))]
head(d)
sum(d[,4])
install.packages(slidify)
install.packages("slidify")
available.packages()
a<-available.packages()
head(a)
find.package("devtools")
library(devtools)
find_rtools
find_rtools()
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "07e73fc66c0f54cb6591",
secret = "d43d70bf2622a6b94028907a9f725a8366aff200")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "07e73fc66c0f54cb6591",
secret = "d43d70bf2622a6b94028907a9f725a8366aff200")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
library(httpuv)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "07e73fc66c0f54cb6591",
secret = "d43d70bf2622a6b94028907a9f725a8366aff200")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
head(req)
jason2 <-jsonlite::fromJSON(toJSON(req))
?toJSON
jason2<-fromjSON(toJSON(req))
jason2<-fromJSON(toJSON(req))
?fromJSON
homeTL <- GET("https://api.github.com/users/jtleek/repos", gtoken)
data <- read.csv("GDP.csv")
country <-read.csv("EDSTATS_Country.csv")
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
rowNames <- seq(10,200, 2)
View(gdp)
fed <- read.csv("EDSTATS_Country.csv")
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
combined[with(combined, order(-V2) )]
combined[with(combined, order(-V2) )]
combined[width(combined, order(-V2) )]
gdp <- read.csv("gdp.csv")
edu <- read.csv("EDSTATS_Country.csv")
names(gdp)
names(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
quantile(mergedData$Gross.domestic.product.2012,probs=c(0.2,0.4,0.6,0.8,1))
library(Hmisc)
mergedData$gdp=cut2(mergedData$Gross.domestic.product.2012,g=5)
table(mergedData$Income.Group,mergedData$gdp)
set.seed(1)
rpois(5,2)
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
x
y <- 0.5 + 2 * x + e
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
install.packages("knitr")
install.packages("slidify")
install.packages("xtable")
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library(ggplot2)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
setwd("E:/CURSOS/REPRODUCIBLE RESEARCH/WEEK 2/Peer Assessment/RepData_PeerAssessment1")
data <- read.csv("activity.csv")
summary(data)
head(data)
str(data)
data <- read.csv("activity.csv", header=T,sep=";", stringsAsFactors=F, na.strings="?",colClasses=c("numeric", "character", "numeric"))
data <- read.csv("activity.csv", header=T,sep=",", stringsAsFactors=F, na.strings="?",colClasses=c("numeric", "character", "numeric"))
data <- read.csv("activity.csv", header=T,sep=",", stringsAsFactors=F, na.strings="?",colClasses=c("numeric", "character", "numeric"))
str(data)
stepsByDay <- tapply(data$steps, data$date, sum, na.rm=TRUE)
hist(stepsByDay)
StepsTotal <- aggregate(steps ~ date, data = data, sum, na.rm = TRUE)
hist(StepsTotal)
hist(StepsTotal$steps)
View(StepsTotal)
View(StepsTotal)
stepsByDay
?cbind
avgstepsperinterval <- tapply(data$steps, data$interval, mean, na.rm = TRUE)
head(avgstepsperinterval)
?impute
??impute
